{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML:  0.1.59\n",
      "Found the config file in: /data/home/aml/notebooks/AML_Workshop/aml_config/config.json\n",
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import azureml\n",
    "from azureml.core import Workspace, Run\n",
    "from azureml.core.model import Model\n",
    "\n",
    "print(\"Azure ML: \", azureml.core.VERSION)\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model model_Linear\n"
     ]
    }
   ],
   "source": [
    "model = Model.register(model_path = \"model_Linear.pickle\",\n",
    "                        model_name = \"model_Linear\",\n",
    "                        tags = {\"data\": \"EngineData\", \"type\": \"classification\"},\n",
    "                        description = \"Predictive Maintenance\",\n",
    "                        workspace = ws)\n",
    "#model = Model(ws, \"model_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can test the Score codes here, and copy this code out and save as Score.py file\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "feature_cols = ['cycle_norm', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "feature_cols = [s for s in feature_cols if s not in ['setting3', 's1', 's5', 's10', 's16', 's18', 's19']]\n",
    "\n",
    "\n",
    "def getTestInput(): # return [?, 26] matrix\n",
    "    dataColumns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "    test_df = pd.read_csv('upload/test_FD001.txt', sep=\" \", header=None)\n",
    "    test_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)\n",
    "    test_df.columns = dataColumns\n",
    "    return test_df\n",
    "\n",
    "def normalizeInputData(test_df): # input [?, 26], output [?, 20]\n",
    "    test_df['cycle_norm'] = test_df['cycle']\n",
    "    cols_normalize = test_df.columns.difference(['id','cycle'])\n",
    "    with open('min_max_scaler.pickle','rb') as f:\n",
    "        min_max_scaler = pickle.load(f)\n",
    "    norm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n",
    "                                columns=cols_normalize, \n",
    "                                index=test_df.index)\n",
    "    test_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n",
    "    test_df = test_join_df.reindex(columns = test_df.columns)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    return test_df[['id','cycle']+feature_cols]\n",
    "\n",
    "\n",
    "def testRun(engine_id=3): # engine 20 is failing, but engine 3 is not at the time of test\n",
    "    test_df = getTestInput()  # [?, 26]\n",
    "    test_df = test_df[test_df['id']==engine_id] # ? filtered by id\n",
    "    #normalize\n",
    "    test_df = normalizeInputData(test_df)  # [?, 20]\n",
    "    # feature engineering\n",
    "    lag_window = 5\n",
    "    lag_cols = [s for s in feature_cols if s not in ['cycle_norm','setting1','setting2','setting3']]\n",
    "    # build lagging features - train data set\n",
    "    df_mean = test_df[lag_cols].rolling(window=lag_window).mean()\n",
    "    df_std = test_df[lag_cols].rolling(window=lag_window).std()\n",
    "    df_mean.columns = ['MA'+s for s in lag_cols]\n",
    "    df_std.columns = ['STD'+s for s in lag_cols]\n",
    "    df_input = pd.concat([test_df,df_mean,df_std], axis=1, join='inner')\n",
    "    input_array = df_input.values[-1:,2:]\n",
    "\n",
    "    with open('model_Linear.pickle','rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    pred_test = model.predict(input_array)\n",
    "    print('prediction: ', pred_test[0])\n",
    "    \n",
    "    \n",
    "def init():\n",
    "    global model\n",
    "    ws = Workspace.from_config()\n",
    "    #model = Model(ws, \"model_Linear\")\n",
    "    #model.download(target_dir = '.')\n",
    "    with open('model_Linear.pickle','rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "def run(test_json):\n",
    "    test_df = pd.read_json(test_json, orient='split') # [?, 26] filtered by id\n",
    "\n",
    "    #normalize\n",
    "    test_df = normalizeInputData(test_df)  # [?, 20]\n",
    "    # feature engineering\n",
    "    lag_window = 5\n",
    "    lag_cols = [s for s in feature_cols if s not in ['cycle_norm','setting1','setting2','setting3']]\n",
    "    # build lagging features - train data set\n",
    "    df_mean = test_df[lag_cols].rolling(window=lag_window).mean()\n",
    "    df_std = test_df[lag_cols].rolling(window=lag_window).std()\n",
    "    df_mean.columns = ['MA'+s for s in lag_cols]\n",
    "    df_std.columns = ['STD'+s for s in lag_cols]\n",
    "    df_input = pd.concat([test_df,df_mean,df_std], axis=1, join='inner')\n",
    "    input_array = df_input.values[-1:,2:]\n",
    "\n",
    "    pred_test = model.predict(input_array)\n",
    "    return json.dumps(int(pred_test[0]))\n",
    "       \n",
    "def testRunJSON(engine_id=3):  \n",
    "    test_df = getTestInput()  # [?, 26]\n",
    "    test_df = test_df[test_df['id']==engine_id] # ? filtered by id\n",
    "    test_df = test_df.tail(5)\n",
    "    \n",
    "    test_json = test_df.to_json(orient='split')\n",
    "    # ... networking, pretend call web service ...\n",
    "    return run(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRunJSON(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
